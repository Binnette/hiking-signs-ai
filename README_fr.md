# ğŸš¶â€â™‚ï¸ DÃ©tection et OCR des Panneaux de RandonnÃ©e ğŸ§­

[ğŸ‡¬ğŸ‡§ English version](README.md)

- Le rÃ©sultat de ce travail peut Ãªtre trouvÃ© dans ce [fichier geojson](./hikingSigns.geojson).
- Ajoutez ces panneaux de randonnÃ©e dans OSM en utilisant ce [dÃ©fi MapRoulette](https://maproulette.org/browse/challenges/49849) ğŸŒ

## Ã€ propos de ce dÃ©pÃ´t ğŸ“š

### Origines ğŸŒŸ

Depuis 2018, j'ai commencÃ© Ã  prendre des photos ğŸ“¸ de chaque panneau de randonnÃ©e que j'ai rencontrÃ© lors de mes randonnÃ©es ğŸ¥¾. Ces types de panneaux, Ã©galement connus sous le nom de poteaux de signalisation :

| Sur un poteau â›³ï¸ | Sur un arbre ğŸŒ³ |
|------------------|-----------------|
| ![Guidepost on a pole](assets/1-guidepost-on-pole.jpg) | ![Guidepost on a tree](assets/2-guidepost-on-tree.jpg) |

Mon idÃ©e originale Ã©tait simplement d'extraire l'emplacement des donnÃ©es Exif de la photo puis de crÃ©er un dÃ©fi MapRoulette simple pour montrer les photos et demander aux contributeurs d'ajouter le poteau de signalisation avec son nom et son altitude â›°ï¸.

Mais dans cette premiÃ¨re idÃ©e, vous devez lire les informations sur la photo et les taper sur votre clavier âŒ¨ï¸. C'est correct si vous ne dÃ©finissez que le nom et l'altitude du poteau de signalisation. Mais cela peut Ãªtre trÃ¨s long si vous voulez crÃ©er la relation de destination avec leur nom, leur distance et leur temps â²ï¸. C'est encore plus long car il peut y avoir beaucoup de destinations diffÃ©rentes sur chaque poteau de signalisation.

Comme j'ai des milliers de photos de poteaux de signalisation ğŸ–¼ï¸, cela prendrait des siÃ¨cles. Alors pourquoi ne pas utiliser l'OCR (reconnaissance de caractÃ¨res) ? Mon premier abord Ã©tait juste un test rapide et salissant. J'ai simplement crÃ©Ã© un script Python ğŸ pour parcourir mes milliers de photos de poteaux de signalisation. Le script exÃ©cutait l'OCR avec la bibliothÃ¨que Python EasyOCR et stockait le rÃ©sultat dans un fichier geojson. Le rÃ©sultat Ã©tait terrible. EasyOCR essayait de reconnaÃ®tre des caractÃ¨res dans chaque partie de l'image, y compris l'arriÃ¨re-plan, la forÃªt ğŸŒ², les panneaux de rue ğŸš, etc.

Exemple de photos contenant du texte indÃ©sirable ğŸ“ :

| Panneau de restriction ğŸš« | Panneau d'indication ğŸ›‘ |
|---------------------------|------------------------|
| ![Picture with unwanted text](assets/3-unwanted-text.jpg) | ![Picture with unwanted text](assets/4-unwanted-text.jpg) |

L'exÃ©cution de l'OCR sur des photos complÃ¨tes Ã©tait une mauvaise idÃ©e, car il essayait de trouver des lettres et des mots partout. J'ai donc dÃ» recadrer âœ‚ï¸ mes milliers d'images aux inscriptions des poteaux de signalisation. Pour ce faire, j'ai entraÃ®nÃ© un modÃ¨le pour reconnaÃ®tre les parties des poteaux de signalisation et aussi les panneaux qui ne m'intÃ©ressaient pas afin de les exclure.

### Ã‰tiqueter les images avec Label Studio ğŸ·ï¸

Installez [Label Studio](https://labelstud.io/) :

```bash
# CrÃ©er et activer un python venv
python -m venv venv
source venv/bin/activate
# Installer et exÃ©cuter label-studio
pip install -U label-studio
label-studio
```

Label Studio s'ouvrira ensuite dans votre navigateur web ğŸŒ.

1. J'ai crÃ©Ã© 2 projets "Hiking Sign Train ğŸš" et "Hiking Sign Test ğŸ§ª".
2. Pour les deux, j'ai sÃ©lectionnÃ© le type `Semantic Segmentation with Polygons` ğŸ“.
3. J'ai crÃ©Ã© mes catÃ©gories et dÃ©fini les ID :

```xml
<View>
  <Header value="SÃ©lectionnez l'Ã©tiquette et cliquez sur l'image pour commencer"/>
  <Image name="image" value="$image" zoom="true" zoomControl="true"/>
  <PolygonLabels name="label" toName="image" strokeWidth="3" pointSize="small" opacity="0.9">
    <Label category="1" value="top" background="#f66151"/>
    <Label category="2" value="destination" background="#dc8add"/>
    <Label category="3" value="poster" background="#2ec27e"/>
    <Label category="4" value="bike_sign" background="#e66100"/>
    <Label category="5" value="street_sign" background="#865e3c"/>
    <Label category="6" value="panel" background="#241f31"/>
  </PolygonLabels>
</View>
```

4. J'ai importÃ© 100 photos dans le projet de formation et 15 dans le projet de test.
5. Ensuite, j'ai commencÃ© Ã  annoter manuellement chaque photo, comme ceci âœï¸ :

| Sans annotation âŒ | Avec annotations âœ”ï¸ |
|--------------------|---------------------|
| ![Without annotation](assets/5-without-annotation.jpg) | ![With annotations](assets/6-with-annotations.jpg) |

J'ai dessinÃ© des polygones autour de chaque Ã©lÃ©ment :
1. **top** : pour le capuchon du poteau de signalisation. Certains poteaux de signalisation n'en ont pas. Le capuchon peut Ãªtre jaune ou vert.
2. **destination** : pour les destinations possibles. En gÃ©nÃ©ral, elles ont un nom, un nombre de kilomÃ¨tres et certaines ont une durÃ©e estimÃ©e en heures. La plupart d'entre elles ont aussi des flÃ¨ches et un fond jaune.
3. **poster** : pour les affiches, gÃ©nÃ©ralement des rÃ©glementations ou pour les chiens ğŸ¶ et les chats ğŸ± perdus.
4. **bike_sign** : pour les panneaux de signalisation dÃ©diÃ©s aux vÃ©los ğŸš´.
5. **street_sign** : pour les rÃ©glementations routiÃ¨res ou les panneaux de nom de rue ğŸš, etc.
6. **panel** : pour les petits panneaux de rÃ©glementation comme pas de feu ğŸ”¥, pas de baignade ğŸŠ, etc.

J'ai annotÃ© Ã  la fois mes photos d'entraÃ®nement et de test et exportÃ© mon projet de Label Studio au format zip COCO. J'ai ensuite extrait les fichiers zip dans les dossiers : `coco-test-hiking-sign` et `coco-train-hiking-sign`.

### PrÃ©parez-vous Ã  entraÃ®ner un modÃ¨le ğŸ–¥ï¸

Ensuite, j'ai Ã©crit un script Python pour entraÃ®ner un modÃ¨le. J'ai utilisÃ© [PyTorch](https://pytorch.org/) et le framework open-source [Detectron2](https://github.com/facebookresearch/detectron2) pour la dÃ©tection d'objets dans mes images.

Tout d'abord, j'ai entraÃ®nÃ© mon modÃ¨le sur mon ordinateur portable ğŸ’», qui est ancien et n'a pas un bon GPU. L'entraÃ®nement a durÃ© 2,5 heures pour seulement 500 itÃ©rations. Ensuite, j'ai utilisÃ© ce modÃ¨le sur mes images, et le rÃ©sultat Ã©tait terrible. Mon modÃ¨le dÃ©tectait Ã  peine les diffÃ©rentes parties du poteau indicateur et les identifiait incorrectement.

Alors, j'ai utilisÃ© un ordinateur de bureau avec un GPU NVIDIA ğŸ®. Comme ce n'Ã©tait pas mon ordinateur, j'ai dÃ» utiliser WSL car `Detectron2` est compatible uniquement avec les systÃ¨mes Linux ğŸ§.

1. Installer [WSL](https://github.com/microsoft/WSL)
2. Installer Ubuntu sur WSL 2+
3. Installer Python, les pilotes NVIDIA et d'autres paquets :

```bash
apt install python3 python3-dev git ubuntu-drivers nvidia-smi
ubuntu-drivers list --gpgpu
# J'ai essayÃ© le pilote 'open' mais il n'a pas fonctionnÃ©
ubuntu-drivers install nvidia:550
# Instructions provenant de https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=WSL-Ubuntu&target_version=2.0&target_type=deb_network
wget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-keyring_1.1-1_all.deb
dpkg -i cuda-keyring_1.1-1_all.deb
apt-get update
apt-get -y install cuda-toolkit-12-6
nvidia-smi
```

4. La derniÃ¨re commande devrait afficher des informations sur votre GPU et la version CUDA.

Maintenant, vous pouvez essayer ce script pour voir si PyTorch peut utiliser votre GPU NVIDIA :

```bash
# Activer l'environnement virtuel Python
source venv/bin/activate
pip wheel
pip install torch torchvision
python 11-testGpu.py
```

Ensuite, j'ai finalement installÃ© Detectron2 :

```bash
git clone https://github.com/facebookresearch/detectron2.git
pip install -e detectron2
```

### EntraÃ®ner un modÃ¨le ğŸ‹ï¸â€â™‚ï¸

```bash
python 20-trainObjectDetectionModel.py
```

Avec 500 itÃ©rations, l'entraÃ®nement a durÃ© 5 minutes sur cet ordinateur au lieu de 2,5 heures sur mon ordinateur portable. Mais le modÃ¨le Ã©tait toujours terrible. Alors, j'ai augmentÃ© le nombre d'itÃ©rations Ã  plus de 5000, l'entraÃ®nement a durÃ© environ 2 heures, et le modÃ¨le Ã©tait "PARFAIT" ğŸ¥³. J'Ã©tais trÃ¨s satisfait du rÃ©sultat.

### Tester mon modÃ¨le ğŸ”¬

J'ai donc testÃ© mon modÃ¨le en l'utilisant pour annoter mes images :

```bash
python 21-testObjectDetectionModel.py
```

Voici une visualisation des objets dÃ©tectÃ©s par mon modÃ¨le :

| DÃ©tection ğŸ” | DÃ©tection ğŸ” |
|--------------|--------------|
| ![AnnotÃ© par le modÃ¨le](assets/7-object-detection.jpg) | ![AnnotÃ© par le modÃ¨le](assets/8-object-detection.jpg) |

Comme vous pouvez le voir, mon modÃ¨le est assez confiant dans la reconnaissance des panneaux supÃ©rieurs et des panneaux de destination des poteaux indicateurs.

### Utiliser le modÃ¨le pour recadrer les images âœ‚ï¸

Maintenant que le modÃ¨le est entraÃ®nÃ©, j'ai Ã©crit un autre script pour recadrer les images selon les zones des panneaux supÃ©rieurs et des destinations donnÃ©es. Il produit des images recadrÃ©es dans les dossiers `crop/top` et `crop/destination`.

```bash
python 22-cropUsingObjectDetectionModel.py
```

### CrÃ©ez un dÃ©fi MapRoulette ğŸŒ

Pour crÃ©er mon dÃ©fi MapRoulette, j'ai besoin de tÃ©lÃ©charger mes photos sur un site web ğŸŒ. Bien sÃ»r, j'ai choisi [Panoramax](https://panoramax.openstreetmap.fr/). J'ai utilisÃ© l'ancien outil en ligne de commande `geovisio` pour tÃ©lÃ©charger mes photos sur Panoramax car il crÃ©e un fichier de rapport `toml`.

Il est maintenant temps de crÃ©er un geojson pour regrouper toutes les informations. Le script suivant :
1. Extrait la latitude et la longitude Ã  partir des donnÃ©es Exif de l'image ğŸ—ºï¸.
2. Extrait l'URL de l'image Panoramax Ã  partir du fichier toml de geovisio ğŸ“.
3. Parcourt chaque image recadrÃ©e et utilise OCR pour extraire le texte ğŸ–‹ï¸.
4. CrÃ©e une fonctionnalitÃ© geojson pour chaque photo ğŸŒ.
5. Enfin, gÃ©nÃ¨re un fichier geojson avec toutes ces donnÃ©es ğŸ“„.

Ensuite, vous pouvez ouvrir ce fichier geojson avec JOSM et le convertir en un fichier `osm`. Utilisez [mr-cli](https://github.com/maproulette/mr-cli) pour convertir ce fichier osm en un fichier geojson de dÃ©fi coopÃ©ratif MapRoulette :

```bash
mr cooperative change --out hikingSignsCoopMrChallenge.json hikingSigns.osm
```

Enfin, crÃ©ez le dÃ©fi sur MapRoulette et tÃ©lÃ©chargez le fichier geojson. Le dÃ©fi peut Ãªtre trouvÃ© ici : [DÃ©fi MapRoulette](https://maproulette.org/browse/challenges/49849) ğŸŒŸ.

# Et aprÃ¨s ? ğŸ”®

- Travaux en cours : utiliser vision llm pour extraire des caractÃ¨res des images au lieu de l'OCR classique ğŸ¤–.
- Corriger les perspectives des panneaux pour amÃ©liorer le fonctionnement de l'OCR ğŸ› ï¸.
