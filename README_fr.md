# ğŸš¶â€â™‚ï¸ DÃ©tection et OCR des Panneaux de RandonnÃ©e ğŸ§­

[ğŸ‡¬ğŸ‡§ English version](README.md)

- Le rÃ©sultat de ce travail peut Ãªtre trouvÃ© dans ce [fichier geojson](./hikingSigns.geojson).
- Ajoutez ces panneaux de randonnÃ©e dans OSM en utilisant ce [dÃ©fi MapRoulette](https://maproulette.org/browse/challenges/49849) ğŸŒ

## Ã€ propos de ce dÃ©pÃ´t ğŸ“š

### Origines ğŸŒŸ

Depuis 2018, j'ai commencÃ© Ã  prendre des photos ğŸ“¸ de chaque panneau de randonnÃ©e que j'ai rencontrÃ© lors de mes randonnÃ©es ğŸ¥¾. Ces types de panneaux, Ã©galement connus sous le nom de poteaux de signalisation :

| Sur un poteau â›³ï¸ | Sur un arbre ğŸŒ³ |
|------------------|-----------------|
| ![Guidepost on a pole](assets/1-guidepost-on-pole.jpg) | ![Guidepost on a tree](assets/2-guidepost-on-tree.jpg) |

Mon idÃ©e originale Ã©tait simplement d'extraire l'emplacement des donnÃ©es Exif de la photo puis de crÃ©er un dÃ©fi MapRoulette simple pour montrer les photos et demander aux contributeurs d'ajouter le poteau de signalisation avec son nom et son altitude â›°ï¸.

Mais dans cette premiÃ¨re idÃ©e, vous devez lire les informations sur la photo et les taper sur votre clavier âŒ¨ï¸. C'est correct si vous ne dÃ©finissez que le nom et l'altitude du poteau de signalisation. Mais cela peut Ãªtre trÃ¨s long si vous voulez crÃ©er la relation de destination avec leur nom, leur distance et leur temps â²ï¸. C'est encore plus long car il peut y avoir beaucoup de destinations diffÃ©rentes sur chaque poteau de signalisation.

Comme j'ai des milliers de photos de poteaux de signalisation ğŸ–¼ï¸, cela prendrait des siÃ¨cles. Alors pourquoi ne pas utiliser l'OCR (reconnaissance de caractÃ¨res) ? Mon premier abord Ã©tait juste un test rapide et salissant. J'ai simplement crÃ©Ã© un script Python ğŸ pour parcourir mes milliers de photos de poteaux de signalisation. Le script exÃ©cutait l'OCR avec la bibliothÃ¨que Python EasyOCR et stockait le rÃ©sultat dans un fichier geojson. Le rÃ©sultat Ã©tait terrible. EasyOCR essayait de reconnaÃ®tre des caractÃ¨res dans chaque partie de l'image, y compris l'arriÃ¨re-plan, la forÃªt ğŸŒ², les panneaux de rue ğŸš, etc.

Exemple de photos contenant du texte indÃ©sirable ğŸ“ :

| Panneau de restriction ğŸš« | Panneau d'indication ğŸ›‘ |
|---------------------------|------------------------|
| ![Picture with unwanted text](assets/3-unwanted-text.jpg) | ![Picture with unwanted text](assets/4-unwanted-text.jpg) |

L'exÃ©cution de l'OCR sur des photos complÃ¨tes Ã©tait une mauvaise idÃ©e, car il essayait de trouver des lettres et des mots partout. J'ai donc dÃ» recadrer âœ‚ï¸ mes milliers d'images aux inscriptions des poteaux de signalisation. Pour ce faire, j'ai entraÃ®nÃ© un modÃ¨le pour reconnaÃ®tre les parties des poteaux de signalisation et aussi les panneaux qui ne m'intÃ©ressaient pas afin de les exclure.

### Ã‰tiqueter les images avec Label Studio ğŸ·ï¸

Installez [Label Studio](https://labelstud.io/) :

```bash
# CrÃ©er et activer un python venv
python -m venv venv
source venv/bin/activate
# Installer et exÃ©cuter label-studio
pip install -U label-studio
label-studio
```

Label Studio s'ouvrira ensuite dans votre navigateur web ğŸŒ.

1. J'ai crÃ©Ã© 2 projets "Hiking Sign Train ğŸš" et "Hiking Sign Test ğŸ§ª".
2. Pour les deux, j'ai sÃ©lectionnÃ© le type `Semantic Segmentation with Polygons` ğŸ“.
3. J'ai crÃ©Ã© mes catÃ©gories et dÃ©fini les ID :

```xml
<View>
  <Header value="SÃ©lectionnez l'Ã©tiquette et cliquez sur l'image pour commencer"/>
  <Image name="image" value="$image" zoom="true" zoomControl="true"/>
  <PolygonLabels name="label" toName="image" strokeWidth="3" pointSize="small" opacity="0.9">
    <Label category="1" value="top" background="#f66151"/>
    <Label category="2" value="destination" background="#dc8add"/>
    <Label category="3" value="poster" background="#2ec27e"/>
    <Label category="4" value="bike_sign" background="#e66100"/>
    <Label category="5" value="street_sign" background="#865e3c"/>
    <Label category="6" value="panel" background="#241f31"/>
  </PolygonLabels>
</View>
```

4. J'ai importÃ© 100 photos dans le projet de formation et 15 dans le projet de test.
5. Ensuite, j'ai commencÃ© Ã  annoter manuellement chaque photo, comme ceci âœï¸ :

| Sans annotation âŒ | Avec annotations âœ”ï¸ |
|--------------------|---------------------|
| ![Without annotation](assets/5-without-annotation.jpg) | ![With annotations](assets/6-with-annotations.jpg) |

J'ai dessinÃ© des polygones autour de chaque Ã©lÃ©ment :
1. **top** : pour le capuchon du poteau de signalisation. Certains poteaux de signalisation n'en ont pas. Le capuchon peut Ãªtre jaune ou vert.
2. **destination** : pour les destinations possibles. En gÃ©nÃ©ral, elles ont un nom, un nombre de kilomÃ¨tres et certaines ont une durÃ©e estimÃ©e en heures. La plupart d'entre elles ont aussi des flÃ¨ches et un fond jaune.
3. **poster** : pour les affiches, gÃ©nÃ©ralement des rÃ©glementations ou pour les chiens ğŸ¶ et les chats ğŸ± perdus.
4. **bike_sign** : pour les panneaux de signalisation dÃ©diÃ©s aux vÃ©los ğŸš´.
5. **street_sign** : pour les rÃ©glementations routiÃ¨res ou les panneaux de nom de rue ğŸš, etc.
6. **panel** : pour les petits panneaux de rÃ©glementation comme pas de feu ğŸ”¥, pas de baignade ğŸŠ, etc.

J'ai annotÃ© Ã  la fois mes photos d'entraÃ®nement et de test et exportÃ© mon projet de Label Studio au format zip COCO. J'ai ensuite extrait les fichiers zip dans les dossiers : `coco-test-hiking-sign` et `coco-train-hiking-sign`.

### PrÃ©parez-vous Ã  entraÃ®ner un modÃ¨le ğŸ–¥ï¸

Ensuite, j'ai Ã©crit un script Python pour entraÃ®ner un modÃ¨le. J'ai utilisÃ© [PyTorch](https://pytorch.org/) et le framework open-source [Detectron2](https://github.com/facebookresearch/detectron2) pour la dÃ©tection d'objets dans mes photos.

D'abord, j'ai entraÃ®nÃ© mon modÃ¨le sur mon ordinateur portable ğŸ’», qui est vieux et n'a pas de bon GPU. L'entraÃ®nement a durÃ© 2,5 heures pour seulement 500 itÃ©rations. Ensuite, j'ai utilisÃ© ce modÃ¨le sur mes photos, et le rÃ©sultat Ã©tait terrible. Mon modÃ¨le dÃ©tectait Ã  peine les diffÃ©rentes parties du poteau de signalisation et les identifiait mal.

J'ai donc utilisÃ© un ordinateur de bureau avec un GPU NVIDIA ğŸ®. Comme ce n'Ã©tait pas mon

I apologize for the interruption. Hereâ€™s the rest of your text translated into French:

### CrÃ©ez un dÃ©fi MapRoulette ğŸŒ

Pour crÃ©er mon dÃ©fi MapRoulette, j'ai besoin de tÃ©lÃ©charger mes photos sur un site web ğŸŒ. Bien sÃ»r, j'ai choisi [Panoramax](https://panoramax.openstreetmap.fr/). J'ai utilisÃ© l'ancien outil en ligne de commande `geovisio` pour tÃ©lÃ©charger mes photos sur Panoramax car il crÃ©e un fichier de rapport `toml`.

Il est maintenant temps de crÃ©er un geojson pour regrouper toutes les informations. Le script suivant :
1. Extrait la latitude et la longitude Ã  partir des donnÃ©es Exif de l'image ğŸ—ºï¸.
2. Extrait l'URL de l'image Panoramax Ã  partir du fichier toml de geovisio ğŸ“.
3. Parcourt chaque image recadrÃ©e et utilise OCR pour extraire le texte ğŸ–‹ï¸.
4. CrÃ©e une fonctionnalitÃ© geojson pour chaque photo ğŸŒ.
5. Enfin, gÃ©nÃ¨re un fichier geojson avec toutes ces donnÃ©es ğŸ“„.

Ensuite, vous pouvez ouvrir ce fichier geojson avec JOSM et le convertir en un fichier `osm`. Utilisez [mr-cli](https://github.com/maproulette/mr-cli) pour convertir ce fichier osm en un fichier geojson de dÃ©fi coopÃ©ratif MapRoulette :

```bash
mr cooperative change --out hikingSignsCoopMrChallenge.json hikingSigns.osm
```

Enfin, crÃ©ez le dÃ©fi sur MapRoulette et tÃ©lÃ©chargez le fichier geojson. Le dÃ©fi peut Ãªtre trouvÃ© ici : [DÃ©fi MapRoulette](https://maproulette.org/browse/challenges/49849) ğŸŒŸ.

# Et aprÃ¨s ? ğŸ”®

- Travaux en cours : utiliser vision llm pour extraire des caractÃ¨res des images au lieu de l'OCR classique ğŸ¤–.
- Corriger les perspectives des panneaux pour amÃ©liorer le fonctionnement de l'OCR ğŸ› ï¸.
